\section{Ramsey theory}

First some fun with limit cases.

Let's define $R_1(s)$ the "Ramsey number for a 1-colouring",
\textit{i.e.} the smallest integer $n$ such that every 1-colouring of $K_n$ yields a monochromatic $K_s$.
It obviously satisfies $R_1(s) = s$, which is equal to $R_2(s,2)$. And more generally
\begin{equation}
    R_k(s_1,\dots,s_{k-1},2) = R_{k-1}(s_1,\dots,s_{k-1}) ,
\end{equation}
where $k \geq 2$. Accepting a complete graph of order 2 for some colour brings no additional constraint on the order of the graph so this colour can be ignored.
Defining $R_1$ has no real interest except that it makes the previous relation more regular (no need to make a special case for $k=2$).
To make this even more regular, could we define $R_0() = 2$? But what would this mean?

We've just seen that the case $s_i = 2$ brings no additional constraint. What about a $s_i = 1$? It should bring even less constraint.
For every $n$, for every colouring there is always a (in fact $n$) monochromatic $K_1$ so
\begin{equation}
    R_k(1,\dots)=1 ,
\end{equation}
for $k \geq 1$.
This condition brings so much less constraint to the problem that there is no more contraint and any $n$ (except 0) satisfies it.
If some $s_i$ is zero, \textit{i.e.} if add even less constraint, really any $n$ is acceptable and $R_k(0,\dots) = 0$.

The situation is similar for hypergraphs made of all \emph{r-tuples} on a set $X$ and noted $X^{(r)}$.
We just have to replace 2 by $r$ and 1 by $\min_i s_i < r$.
Previous equation generalizes as follows
\begin{align}
    \label{eq:ramseyLimitR}
    R_k^{(r)}(s_1,\dots,s_{k-1},r) & = R_{k-1}^{(r)}(s_1,\dots,s_{k-1}) \\
    \label{eq:ramseyLimitMin}
    R_k^{(r)}(s_1,\dots,s_1) & = \min_i s_i \qquad \text{if} \min_i s_i < r .
\end{align}

The case $r = 1$ is difficult to picture if we think of (hyper) graphs as (generalized) lines between points.
However, if we think of $r$-sets, it becomes very natural: $X^{(1)}$ is made of all singletons of $X$.
The Ramsey number for 2-colourings of $X^{(1)}$ is $s+t-1$, which generalizes to
\begin{equation}
    \label{eq:ramseyLimitR1}
    R_k^{(1)}(s_1,\dots,s_k) = s_1 + \dots + s_k - k + 1
\end{equation}
and satifies equations (\ref{eq:ramseyLimitR}) and (\ref{eq:ramseyLimitMin}).

\subsection{Theorem 1}

Here is how I tried to prove the first part of theorem 1.

Let's assume that $R(s-1,t)$ and $R(s,t-1)$ are finite. Let's consider two 2-colourings on $K_{n_1}$ and $K_{n_2}$ with $n_1 = R(s-1,t)$ and $n_2 = R(s,t-1)$ and build a 2-colouring on $K_{n_1 + n_2}$ from them.
If the first graph contains a blue subgraph of size $t$ or the second graph contains a red subgraph of size $s$ then we are done.
Otherwise, they contain respectively a red subgraph of size $s-1$ and a blue subgraph of size $t-1$.
I now want to prove that when we connect graphs $K_{n_1}$ and $K_{n_2}$,
either the red $K_{s-1]}$ is connected (with only red edges) to a vertex of $K_{n_2}$ to yield a red $K_s$
or the blue $K_{t-1}$ is connected (with with only blue edges) to a vertex of $K_{n_1}$ to yield a blue $K_t$.

Let's assume that there is no vertex in $K_{n_2}$ that can be connected to $K_{s-1}$ with only red edges.
Then for every vertex in $K_{n_2}$ there is at least one blue edge to $K_{s-1}$.
How can this guarantee that there is a vertex in $K_{n_1}$ connected to $K_{t-1}$ with only blue edges?
I don't think it can so my proof seems to be doomed.

I think the problem with my (tentative of) proof is that I forced an extra partition of $K_{n_1+n_2}$ into $K_{n_1}$ and $K_{n_2}$
such that the red $K_s$ has $s-1$ vertices in $K_{n_1}$ (or the blue $K_t$ has $t-1$ vertices in $K_{n_2}$).
This is an additional constraint which is not fullfilled for every colouring.
Also, it focuses only on a red $K_{s-1}$ in $K_{n_1}$ and a blue $K_{t-1}$ in $K_{n_2}$ and ignores anything else.
The $K_s$ (or the $K_t$) may be spread differently on the two parts.

\medskip

The generalization of the first part of the theorem (and its proof) to the case of k-colouring is easy
\begin{equation}
    \label{eq:generalRamseyUpperBound}
    R_k(s_1,\dots,s_k) \leq R_k(s_1-1,\dots,s_k) + \dots + R_k(s_1,\dots,s_k-1) .
\end{equation}

Let's try to generalize the second part of the theorem to k-colourings too.
I'm expecting
\begin{equation}
    \label{eq:generalRamseyUpperBoundMultinomial}
    R_k(s_1,\dots,s_k) \leq
    \left(
    \begin{matrix}
        s_1+\dots+s_k-k \\
        s_1-1,\dots,s_k-1
    \end{matrix}
    \right) .
\end{equation}
Let's show this for $k=3$. If $s_3 = 2$ then $R_3(s_1,s_2,2) = R(s_1,s_2)$ and since
\begin{multline}
    \left(
    \begin{matrix}
        s_1+s_2-2 \\
        s_1-1
    \end{matrix}
    \right) =
    \left(
    \begin{matrix}
        s_1+s_2-2 \\
        s_1-1,s_2-1
    \end{matrix}
    \right)
    =
    \left(
    \begin{matrix}
        s_1+s_2+s_3-4 \\
        s_1-1,s_2-1,s_3-2
    \end{matrix}
    \right) \\
    \leq
    \left(
    \begin{matrix}
        s_1+s_2+s_3-3 \\
        s_1-1,s_2-1,s_3-1
    \end{matrix}
    \right)
    \nonumber
\end{multline}
the inequality holds.
Now let's assume it holds for any $s'_i > 2$ such that $s'_1+s'_2+s'_3 < s_1+s_2+s_3$, then from equation (\ref{eq:generalRamseyUpperBound}) and
\begin{equation}
    \left(
    \begin{matrix}
        s \\
        s_1,s_2,s_3
    \end{matrix}
    \right) =
    \left(
    \begin{matrix}
        s-1 \\
        s_1-1_,s_2,s_3
    \end{matrix}
    \right) +
    \left(
    \begin{matrix}
        s-1 \\
        s_1,s_2-1,s_3
    \end{matrix}
    \right) +
    \left(
    \begin{matrix}
        s-1 \\
        s_1,s_2,s_3-1
    \end{matrix}
    \right) , \nonumber
\end{equation}
where $s=s_1+s_2+s_3$, the inequality holds.
The same proof should work for any $k$.

\medskip

Another way of proving that $R_k$ is finite is by colour grouping as shown after the proof of theorem 1.
And since there are several ways of grouping colours, there are several upper bounds
\begin{align}
    R_k(s_1,\dots,s_k) & \leq R_{k-1}(R_2(s_1,s_2),\dots,s_k) \\
    R_k(s_1,\dots,s_k) & \leq R_{k-2}(R_3(s_1,s_2,s_3),\dots,s_k)) \\
    \dots \nonumber \\
    R_k(s_1,\dots,s_k) & \leq R_2(R_{k-1}(s_1,\dots,s_{k-1}),s_k) ,
\end{align}
and these are not all possible combinations.
Note that for $k=2$, the inequality is an equality
\begin{equation}
    R_2(s_1,s_2) = R_1(R_2(s_1,s_2)) .
\end{equation}
However it is a useless equality.
Which are the best upper bounds? One of these? Or the one obtained by generalizing the proof of theorem 1 to $k$-colourings?
Intuitively I would say that equation (\ref{eq:generalRamseyUpperBound}) is the best upper bound.
By construction equation (\ref{eq:generalRamseyUpperBoundMultinomial}) cannot be better.
And other upper bounds are made of a fast-growing function calling another fast-growing function in its arguments:
they are probably very fast-growing function.

\subsection{Theorem 2}

Theorem 2 is a generalization of the first part of theorem 1 to hypergraphs.
The two proofs are indeed very similar.
But to make it even more obvious let's rewrite the first  part of theorem 1 as
\begin{equation}
    R^{(2)}(s,t) \leq R^{(1)}(R^{(2)}(s-1,t)+R^{(2)}(s,t-1))+1
    \nonumber
\end{equation}
thanks to equation (\ref{eq:ramseyLimitR1}).
The proof of theorem 2 is then identical to the one of theorem 1 with $r=2$.

I can see no (at least no obvious) generalization of the second part of theorem 1.
Indeed, this was based on the fact that the upper bound of $R(s,t)$ follows the same recursion relation as the binomial coefficients.
But I cannot see any obvious generalization of the binomial coefficients obeying the same recursion relation as the upper bound of $R^{(r)}(s,t)$.

\medskip

Let's now derive upper bounds of $R_k^{(r)}$ by colour grouping and by generalizing theorem 2 (cf. Exercise 8).

Colour grouping is done the same way as for graphs. We thus obtain the same inequalities
\begin{equation}
    R_k^{(r)}(s_1,\dots,s_k) \leq R_{k-1}^{(r)}(R_2^{(r)}(s_1,s_2),\dots,s_k) .
\end{equation}
As for graphs, the grouping of colours can be done in several ways so there are several upper bounds.

The generalization of the proof of theorem 2 looks like this.
Let $X$ be a set such as $\left|X\right| = R_k^{(r-1)}(R_k^{(r)}(s_1-1,\dots),\dots,R_k^{(r)}(\dots,s_k-1))+1$ and $c$ a $k$-colouring on $X^{(r)}$
and let $x$ be an element of $X$.
Let $Y$ be the set $X \setminus \{x\}$.
Colouring $c$ induces a colouring $c'$ on $Y^{(r-1)}$ such that the colour of $\sigma \in Y^{(r-1)}$ in $c'$ is the colour of $\sigma \cup \{x\} \in X^{(r)}$ in $c$.
By construction of $Y$, there is a monochromatic $r-1$-set $Z \subset Y$ with size $R_k^{r}(s_1\dots,s_i-1,\dots,s_k)$ with colour $i$ for colouring $c'$.
Let's now move back to colouring $c$ and more precisely to its restriction to $Z^{(r)}$.
$Z^{(r)}$ either has a monochromatic $r$-set with colour $j \neq i$ and size $s_j$, in which case we are done, or a monochromatic $r$-set with colour $i$ and size $s_i-1$.
In the second case, $Z \cup \{x\}$ is a monochromatic $r$-set with colour $i$ in $c$.
Which proves
\begin{multline}
    R_k^{(r)}(s_1,\dots,s_k)) \leq \\
    R_k^{(r-1)}(R_k^{(r)}(s_1-1,\dots),\dots,R_k^{(r)}(\dots,s_k-1)) + 1 .
\end{multline}

To better understand this proof I need at least one example with $r=3$.
Let's assume we have a red 2-set $\{z_1,z_2,z_3\}$.
This means that we have red sets $\{z_1,z_2\}$, $\{z_1,z_3\}$ and $\{z_2,z_3\}$ in $c'$.
In $c$, we thus have these red sets: $\{x,z_1,z_2\}$, $\{x,z_1,z_3\}$ and $\{x,z_2,z_3\}$.
However these are not enough for $\{x,z_1,z_2,z_3\}$ to be a red 3-set.
Indeed, the red set $\{z_1,z_2,z_3\}$ must be present too.
That's why, once we have found a monochromatic (for colouring $c'$)) $r-1$-set $Z$ we still have to find a monochromatic (for $c$) $r$-set inside $Z$.
And that's why set $Z$ must be quite big.